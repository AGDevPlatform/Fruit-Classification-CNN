{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6V1o_qFCBqxw"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import random\n",
        "import shutil\n",
        "import time\n",
        "import warnings\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.distributed as dist\n",
        "import torch.optim\n",
        "import torch.utils.data\n",
        "import torch.utils.data.distributed\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3VTsl34CA25",
        "outputId": "597508ac-4f9c-4a3c-aa11-b0155897e2af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gfYwM2yECFsR"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/ML/')\n",
        "import writeLogAcc as wA\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/ML/models/')\n",
        "from cross_entropy import LabelSmoothingCrossEntropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jh0JXG9HCJ04",
        "outputId": "a34f6a79-a037-4b4b-de87-11dbefba1587"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model\n",
            "Net(\n",
            "  (conv0): Conv2d(3, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
            "  (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv7): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv8): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv9): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv10): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv11): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (maxpool2): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
            "  (avgpool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (avgpool2): AvgPool2d(kernel_size=2, stride=4, padding=0)\n",
            "  (fc1): Linear(in_features=9408, out_features=1204, bias=True)\n",
            "  (fc2): Linear(in_features=1204, out_features=10, bias=True)\n",
            "  (relu): ReLU()\n",
            ")\n",
            "Number of model parameters: 17633094\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 224, 224]           4,736\n",
            "            Conv2d-2         [-1, 64, 112, 112]          18,496\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "            Conv2d-4        [-1, 128, 112, 112]          73,856\n",
            "              ReLU-5        [-1, 128, 112, 112]               0\n",
            "            Conv2d-6        [-1, 128, 112, 112]         147,584\n",
            "              ReLU-7        [-1, 128, 112, 112]               0\n",
            "            Conv2d-8        [-1, 128, 112, 112]         147,584\n",
            "              ReLU-9        [-1, 128, 112, 112]               0\n",
            "           Conv2d-10        [-1, 256, 112, 112]         295,168\n",
            "             ReLU-11        [-1, 256, 112, 112]               0\n",
            "           Conv2d-12        [-1, 256, 112, 112]         590,080\n",
            "             ReLU-13        [-1, 256, 112, 112]               0\n",
            "        MaxPool2d-14          [-1, 256, 56, 56]               0\n",
            "           Conv2d-15          [-1, 512, 56, 56]       1,180,160\n",
            "             ReLU-16          [-1, 512, 56, 56]               0\n",
            "           Conv2d-17          [-1, 256, 56, 56]       1,179,904\n",
            "             ReLU-18          [-1, 256, 56, 56]               0\n",
            "           Conv2d-19          [-1, 512, 56, 56]       1,180,160\n",
            "             ReLU-20          [-1, 512, 56, 56]               0\n",
            "           Conv2d-21          [-1, 256, 56, 56]       1,179,904\n",
            "             ReLU-22          [-1, 256, 56, 56]               0\n",
            "        AvgPool2d-23          [-1, 512, 28, 28]               0\n",
            "           Conv2d-24           [-1, 64, 28, 28]         294,976\n",
            "        MaxPool2d-25          [-1, 128, 28, 28]               0\n",
            "        AvgPool2d-26            [-1, 192, 7, 7]               0\n",
            "           Linear-27                 [-1, 1204]      11,328,436\n",
            "             ReLU-28                 [-1, 1204]               0\n",
            "           Linear-29                   [-1, 10]          12,050\n",
            "================================================================\n",
            "Total params: 17,633,094\n",
            "Trainable params: 17,633,094\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 279.93\n",
            "Params size (MB): 67.26\n",
            "Estimated Total Size (MB): 347.77\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/ML/models/')  # Add models directory to path\n",
        "#from models.Nhom12Mang1 import *\n",
        "from torchsummary import summary\n",
        "# from models.Nhom12Mang1 import *\n",
        "#Thay đổi mạng tại đây học import\n",
        "#Mạng 1\n",
        "class Net(nn.Module):\n",
        "      def __init__(self, n_class=10):\n",
        "          super(Net, self).__init__()\n",
        "          self.conv0 = nn.Conv2d(3, 32, kernel_size=7, padding=3, stride=1)\n",
        "          self.conv1 = nn.Conv2d(32, 64, kernel_size=3, padding=1, stride=2)\n",
        "          self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "          self.conv3 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "          self.conv4 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "          self.conv5 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "          self.conv6 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "          self.conv7 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
        "          self.conv8 = nn.Conv2d(512, 256, kernel_size=3, padding=1)\n",
        "          self.conv9 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
        "          self.conv10 = nn.Conv2d(512, 256, kernel_size=3, padding=1)\n",
        "          self.conv11 = nn.Conv2d(512, 64, kernel_size=3, padding=1)\n",
        "          self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "          self.maxpool2 = nn.MaxPool2d(kernel_size=4, stride=4)\n",
        "          self.avgpool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "          self.avgpool2 = nn.AvgPool2d(kernel_size=2, stride=4)\n",
        "          self.fc1 = nn.Linear(9408, 1204)\n",
        "          self.fc2 = nn.Linear(1204, n_class)\n",
        "          self.relu = nn.ReLU()\n",
        "      def forward(self, x):\n",
        "          x = self.conv0(x)\n",
        "\n",
        "          x1 = self.relu(self.conv1(x))\n",
        "          x2 = self.relu(self.conv2(x1))\n",
        "          x3 = self.relu(self.conv3(x2))\n",
        "          x4 = self.relu(self.conv4(x3))\n",
        "\n",
        "          x_add1 = x2 + x4\n",
        "\n",
        "          x5 = self.relu(self.conv5(x_add1))\n",
        "          x6 = self.relu(self.conv6(x5))\n",
        "          x7 = self.maxpool1(x6)\n",
        "          x8 = self.relu(self.conv7(x7))\n",
        "          x9 = self.relu(self.conv8(x8))\n",
        "\n",
        "          x_add2 = x7 + x9\n",
        "\n",
        "          x10 = self.relu(self.conv9(x_add2))\n",
        "          x11 = self.relu(self.conv10(x10))\n",
        "\n",
        "          x_cat1 = torch.cat((x_add2, x11), dim=1)\n",
        "\n",
        "          x_avg1 = self.avgpool1(x_cat1)\n",
        "          x_avg1 = self.conv11(x_avg1)\n",
        "\n",
        "          x_add1 = self.maxpool2(x_add1)\n",
        "          x_cat2 = torch.cat((x_add1, x_avg1), dim=1)\n",
        "          x_avg2 = self.avgpool2(x_cat2)\n",
        "\n",
        "          x_flat = x_avg2.view(x_avg2.size(0), -1)\n",
        "          x_fc1 = self.relu(self.fc1(x_flat))\n",
        "          x_out = self.fc2(x_fc1)\n",
        "          return x_out\n",
        "\n",
        "#Mang 2\n",
        "# class Net(nn.Module):\n",
        "#     def __init__(self, n_classes=10):\n",
        "#         super(Net, self).__init__()\n",
        "#         #Mang 2\n",
        "#         self.conv0 = nn.Conv2d(3, 32, kernel_size=7, padding=3, stride=1)\n",
        "#         self.conv1 = nn.Conv2d(32, 64, kernel_size=5, padding=2)  # Conv1\n",
        "#         self.conv2 = nn.Conv2d(64, 64, kernel_size=5, padding=2)  # Conv2\n",
        "#         self.conv3 = nn.Conv2d(64, 64, kernel_size=5, padding=2)  # Conv3\n",
        "#         self.conv4 = nn.Conv2d(64, 128, kernel_size=5, padding=2)  # Conv4\n",
        "#         self.conv5 = nn.Conv2d(128, 256, kernel_size=5, padding=2)  # Conv5\n",
        "#         self.conv6 = nn.Conv2d(256, 256, kernel_size=5, padding=2)  # Conv6\n",
        "#         self.conv7 = nn.Conv2d(256, 256, kernel_size=5, padding=2)  # Conv7\n",
        "#         self.conv8 = nn.Conv2d(256, 512, kernel_size=5, padding=2)  # Conv8\n",
        "#         self.conv9 = nn.Conv2d(512, 256, kernel_size=5, padding=2)  # Conv9\n",
        "#         self.conv10 = nn.Conv2d(256, 128, kernel_size=5, padding=2)  # Conv10\n",
        "\n",
        "#         # Pooling layers\n",
        "#         self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "#         self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "#         self.avgpool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "#         # Fully connected layer\n",
        "#         self.fc = nn.Linear(301056, n_classes)\n",
        "\n",
        "#         # Activation\n",
        "#         self.relu = nn.ReLU()\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         # Stage 1\n",
        "#         x = self.conv0(x)\n",
        "#         x1 = self.relu(self.conv1(x))  # Conv1\n",
        "#         x2 = self.relu(self.conv2(x1))  # Conv2\n",
        "#         x3 = self.relu(self.conv3(x2))  # Conv3\n",
        "\n",
        "#         # Tensor addition 1\n",
        "#         x_add1 = x1 + x3\n",
        "\n",
        "#         # Stage 2\n",
        "#         x4 = self.relu(self.conv4(x_add1))  # Conv4\n",
        "#         x5 = self.relu(self.conv5(x4))  # Conv5\n",
        "#         x6 = self.maxpool1(x5)  # Maxpool1\n",
        "\n",
        "#         # Stage 3\n",
        "#         x7 = self.relu(self.conv6(x6))  # Conv6\n",
        "#         x8 = self.relu(self.conv7(x7))  # Conv7\n",
        "\n",
        "#         # Tensor addition 2\n",
        "#         x_add2 = x6 + x8\n",
        "\n",
        "#         # Stage 4\n",
        "#         x9 = self.relu(self.conv8(x_add2))  # Conv8\n",
        "#         x10 = self.relu(self.conv9(x9))  # Conv9\n",
        "#         x11 = self.relu(self.conv10(x10))  # Conv10\n",
        "\n",
        "#         # Concatenation\n",
        "#         x_cat = torch.cat((x11, x10), dim=1)\n",
        "\n",
        "#         # Average pooling\n",
        "#         x_avg = self.avgpool(x_cat)\n",
        "\n",
        "#         # Maxpool2\n",
        "#         x_pool = self.maxpool2(x_avg)\n",
        "\n",
        "#         x_flat = x_pool.view(x_pool.size(0), -1)\n",
        "\n",
        "#         x_out = self.fc(x_flat)\n",
        "#         return x_out\n",
        "\n",
        "#Mang 3\n",
        "\n",
        "# class Net(nn.Module):\n",
        "#       def __init__(self, n_class=10):\n",
        "#           super(Net, self).__init__()\n",
        "#           self.conv0 = nn.Conv2d(in_channels = 3, out_channels = 32, kernel_size = 7, stride=1, padding=3)\n",
        "#           self.conv1 = nn.Conv2d(in_channels = 32, out_channels = 32, kernel_size = 3, stride=1, padding=0)\n",
        "#           self.conv2 = nn.Conv2d(in_channels = 32, out_channels = 32, kernel_size = 3, stride=1, padding=0)\n",
        "#           self.conv3 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 5, stride=2, padding=4)\n",
        "#           self.conv4 = nn.Conv2d(in_channels = 32, out_channels = 32, kernel_size = 3, stride=2, padding=1)\n",
        "#           self.conv5 = nn.Conv2d(in_channels = 32, out_channels = 32, kernel_size = 5, stride=2, padding=2)\n",
        "#           self.conv6 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride=2, padding=1)\n",
        "#           self.conv7 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 5, stride=2, padding=2)\n",
        "#           self.conv8 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 5, stride=2, padding=2)\n",
        "#           self.conv9 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride=1, padding=2)\n",
        "#           self.conv10 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 5, stride=1, padding=1)\n",
        "\n",
        "#           self.conv11 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 5, stride=1, padding=4)\n",
        "#           self.conv12 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 5, stride=1, padding=4)\n",
        "#           self.conv13 = nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size = 3, stride=1, padding=3)\n",
        "#           self.conv14 = nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size = 3, stride=1, padding=3)\n",
        "#           self.conv15 = nn.Conv2d(in_channels = 192, out_channels = 192, kernel_size = 5, stride=1, padding=2)\n",
        "#           self.conv16 = nn.Conv2d(in_channels = 192, out_channels = 192, kernel_size = 5, stride=1, padding=2)\n",
        "#           self.conv17 = nn.Conv2d(in_channels = 192, out_channels = 192, kernel_size = 3, stride=1, padding=2)\n",
        "#           self.conv18 = nn.Conv2d(in_channels = 192, out_channels = 192, kernel_size = 3, stride=1, padding=2)\n",
        "#           self.conv19 = nn.Conv2d(in_channels = 192, out_channels = 80, kernel_size = 3, stride=2, padding=3)\n",
        "#           self.conv20 = nn.Conv2d(in_channels = 192, out_channels = 80, kernel_size = 5, stride=2, padding=4)\n",
        "\n",
        "#           self.avgpool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "#           self.avgpool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "#           self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "#           self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "#           self.fc1 = nn.Linear(9 * 9 * 160, 1024)\n",
        "#           self.fc2 = nn.Linear(1024, 10)\n",
        "#           self.relu = nn.ReLU()\n",
        "#       def forward(self, x):\n",
        "#           conv0_x = self.conv0(x)\n",
        "#           conv1_x = F.relu(self.conv1(conv0_x))\n",
        "#           conv2_x = F.relu(self.conv2(conv1_x))\n",
        "#           conv3_x = F.relu(self.conv3(conv2_x))\n",
        "#           conv4_x = F.relu(self.conv4(conv0_x))\n",
        "#           conv7_x = F.relu(self.conv7(conv4_x))\n",
        "#           conv5_x = F.relu(self.conv5(conv1_x))\n",
        "#           conv6_x = F.relu(self.conv6(conv3_x))\n",
        "#           conv8_x = F.relu(self.conv8(conv5_x))\n",
        "\n",
        "#           top_left_sum_x = conv7_x + conv8_x\n",
        "#           top_right_sum_x = conv6_x + conv8_x\n",
        "\n",
        "#           conv9_x = F.relu(self.conv9(conv8_x))\n",
        "#           conv10_x = F.relu(self.conv10(conv9_x))\n",
        "\n",
        "#           bottom_left_sum_x = top_left_sum_x + conv10_x\n",
        "#           bottom_right_sum_x = top_right_sum_x + conv10_x\n",
        "\n",
        "#           conv11_x = F.relu(self.conv11(bottom_left_sum_x))\n",
        "#           top_left_cat_x = torch.cat((bottom_left_sum_x, conv10_x), dim=1)\n",
        "#           top_right_cat_x = torch.cat((bottom_right_sum_x, conv10_x), dim=1)\n",
        "\n",
        "#           conv12_x = F.relu(self.conv12(bottom_right_sum_x))\n",
        "#           conv13_x = F.relu(self.conv13(top_left_cat_x))\n",
        "#           conv14_x = F.relu(self.conv14(top_right_cat_x))\n",
        "\n",
        "#           bottom_left_cat_x = torch.cat((conv11_x, conv13_x), dim=1)\n",
        "#           bottom_right_cat_x = torch.cat((conv12_x, conv14_x), dim=1)\n",
        "\n",
        "#           conv15_x = F.relu(self.conv15(bottom_left_cat_x))\n",
        "#           conv16_x = F.relu(self.conv16(bottom_right_cat_x))\n",
        "\n",
        "#           avgpool1_x = self.avgpool1(conv15_x)\n",
        "#           avgpool2_x = self.avgpool2(conv16_x)\n",
        "\n",
        "#           conv17_x = F.relu(self.conv17(avgpool1_x))\n",
        "#           conv18_x = F.relu(self.conv18(avgpool2_x))\n",
        "\n",
        "#           conv19_x = F.relu(self.conv19(conv17_x))\n",
        "#           conv20_x = F.relu(self.conv20(conv18_x))\n",
        "\n",
        "#           maxpool1_x = self.maxpool1(conv19_x)\n",
        "#           maxpool2_x = self.maxpool2(conv20_x)\n",
        "\n",
        "#           final_cat_x = torch.cat((maxpool1_x, maxpool2_x), dim=1)\n",
        "\n",
        "#           view_x = final_cat_x.view(-1, 9 * 9 * 160)\n",
        "\n",
        "#           fc1_x = F.relu(self.fc1(view_x))\n",
        "#           fc2_x = self.fc2(fc1_x)\n",
        "\n",
        "\n",
        "#           return fc2_x\n",
        "\n",
        "model = Net()\n",
        "model = model.cuda()\n",
        "print (\"model\")\n",
        "print (model)\n",
        "\n",
        "# get the number of model parameters\n",
        "print('Number of model parameters: {}'.format(\n",
        "    sum([p.data.nelement() for p in model.parameters()])))\n",
        "#print(model)\n",
        "#model.cuda()\n",
        "summary(model, (3, 224, 224))\n",
        "\n",
        "#Dùng CPU\n",
        "# model = model.to('cpu')  # Hoặc model = model.cpu()\n",
        "\n",
        "# print(\"Model\")\n",
        "# print(model)\n",
        "\n",
        "# # get the number of model parameters\n",
        "# print('Number of model parameters: {}'.format(\n",
        "#     sum([p.data.nelement() for p in model.parameters()])))\n",
        "\n",
        "# # Sử dụng device='cpu' khi gọi summary\n",
        "# summary(model, (3, 224, 224), device='cpu')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oML_0KzoCPV3",
        "outputId": "b22212be-d7b7-4e34-9856-3aca9a15d157"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ptflops\n",
            "  Downloading ptflops-0.7.4-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.10/dist-packages (from ptflops) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->ptflops) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->ptflops) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->ptflops) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->ptflops) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->ptflops) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->ptflops) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.0->ptflops) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0->ptflops) (3.0.2)\n",
            "Downloading ptflops-0.7.4-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: ptflops\n",
            "Successfully installed ptflops-0.7.4\n"
          ]
        }
      ],
      "source": [
        "!pip install ptflops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvY0UpjaCSvx",
        "outputId": "0666e192-f577-4a99-d0a3-64f779d803c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: module Net is treated as a zero-op.\n",
            "Net(\n",
            "  17.62 M, 100.000% Params, 31.27 GMac, 99.925% MACs, \n",
            "  (conv0): Conv2d(4.74 k, 0.027% Params, 0.24 GMac, 0.759% MACs, 3, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
            "  (conv1): Conv2d(18.5 k, 0.105% Params, 0.23 GMac, 0.741% MACs, 32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (conv2): Conv2d(73.86 k, 0.419% Params, 0.93 GMac, 2.960% MACs, 64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3): Conv2d(147.58 k, 0.837% Params, 1.85 GMac, 5.916% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv4): Conv2d(147.58 k, 0.837% Params, 1.85 GMac, 5.916% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv5): Conv2d(295.17 k, 1.675% Params, 3.7 GMac, 11.831% MACs, 128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv6): Conv2d(590.08 k, 3.348% Params, 7.4 GMac, 23.652% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv7): Conv2d(1.18 M, 6.696% Params, 3.7 GMac, 11.826% MACs, 256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv8): Conv2d(1.18 M, 6.695% Params, 3.7 GMac, 11.824% MACs, 512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv9): Conv2d(1.18 M, 6.696% Params, 3.7 GMac, 11.826% MACs, 256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv10): Conv2d(1.18 M, 6.695% Params, 3.7 GMac, 11.824% MACs, 512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv11): Conv2d(294.98 k, 1.674% Params, 0.23 GMac, 0.739% MACs, 512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (maxpool1): MaxPool2d(0, 0.000% Params, 0.0 GMac, 0.010% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (maxpool2): MaxPool2d(0, 0.000% Params, 0.0 GMac, 0.005% MACs, kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
            "  (avgpool1): AvgPool2d(0, 0.000% Params, 0.0 GMac, 0.005% MACs, kernel_size=2, stride=2, padding=0)\n",
            "  (avgpool2): AvgPool2d(0, 0.000% Params, 0.0 GMac, 0.000% MACs, kernel_size=2, stride=4, padding=0)\n",
            "  (fc1): Linear(11.33 M, 64.276% Params, 0.01 GMac, 0.036% MACs, in_features=9408, out_features=1204, bias=True)\n",
            "  (fc2): Linear(3.62 k, 0.021% Params, 0.0 GMac, 0.000% MACs, in_features=1204, out_features=3, bias=True)\n",
            "  (relu): ReLU(0, 0.000% Params, 0.02 GMac, 0.054% MACs, )\n",
            ")\n",
            "Computational complexity (MACs):   31.3 GMac\n",
            "Floating-point operations (FLOPs):   15.65 G \n",
            "Number of parameters:           17.62 M \n",
            "Number of model parameters (referred)): 17624659\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from ptflops import get_model_complexity_info\n",
        "from torchsummary import summary\n",
        "#from models.Nhom12Mang1 import *\n",
        "with torch.cuda.device(0):\n",
        "\n",
        "  model = Net(3)\n",
        "  #macs, params = get_model_complexity_info(model, (3, 32, 32), as_strings=True,\n",
        "  macs, params = get_model_complexity_info(model, (3, 224, 224), as_strings=True,\n",
        "                                           print_per_layer_stat=True, verbose=True,\n",
        "                                           #flops_units='MMac')\n",
        "                                           flops_units='GMac')\n",
        "  print('{:<30}  {:<8}'.format('Computational complexity (MACs): ', macs))\n",
        "  macs1 = macs.split()\n",
        "  strmacs1=str(float(macs1[0])/2) + ' ' + macs1[1][0]\n",
        "  print('{:<30}  {:<8}'.format('Floating-point operations (FLOPs): ', strmacs1))\n",
        "  print('{:<30}  {:<8}'.format('Number of parameters: ', params))\n",
        "\n",
        "  print('Number of model parameters (referred)): {}'.format(\n",
        "      sum([p.data.nelement() for p in model.parameters()])))\n",
        "  #summary(model, (3, 224, 224))\n",
        "# Chuyển sang sử dụng CPU\n",
        "# device = torch.device('cpu')\n",
        "\n",
        "# # Khởi tạo model trên CPU\n",
        "# model = Net(3).to(device)\n",
        "\n",
        "# # Sử dụng get_model_complexity_info với input size phù hợp\n",
        "# macs, params = get_model_complexity_info(model, (3, 224, 224), as_strings=True,\n",
        "#                                           print_per_layer_stat=True, verbose=True,\n",
        "#                                           flops_units='GMac')\n",
        "\n",
        "# print('{:<30} {:<8}'.format('Computational complexity (MACs): ', macs))\n",
        "# macs1 = macs.split()\n",
        "# strmacs1 = str(float(macs1[0])/2) + ' ' + macs1[1][0]\n",
        "# print('{:<30} {:<8}'.format('Floating-point operations (FLOPs): ', strmacs1))\n",
        "# print('{:<30} {:<8}'.format('Number of parameters: ', params))\n",
        "\n",
        "# print('Number of model parameters (referred)): {}'.format(\n",
        "#     sum([p.data.nelement() for p in model.parameters()])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOivLb-NCWjx",
        "outputId": "c76c2652-b14a-4f7a-e5fa-0ea8ea83bc5b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['--action'], dest='action', nargs=None, const=None, default='', type=<class 'str'>, choices=None, required=False, help='other information.', metavar=None)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2\"  # specify which GPU(s) to be used\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"  # specify which GPU(s) to be used\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,2\"  # specify which GPU(s) to be used\n",
        "parser = argparse.ArgumentParser(description='PyTorch ImageNet Training')\n",
        "# Remove GPU-related arguments or set them to None\n",
        "parser = argparse.ArgumentParser(description='PyTorch ImageNet Training')\n",
        "parser.add_argument('-r', '--data', type=str, default='/content/drive/MyDrive/ML/dataset/', help='path to dataset')\n",
        "parser.add_argument('-j', '--workers', default=16, type=int, metavar='N',\n",
        "                    help='number of data loading workers (default: 4)')\n",
        "parser.add_argument('--epochs', default=50, type=int, metavar='N',\n",
        "                    help='number of total epochs to run')\n",
        "parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
        "                    help='manual epoch number (useful on restarts)')\n",
        "#parser.add_argument('-b', '--batch-size', default=256, type=int,\n",
        "parser.add_argument('-b', '--batch-size', default=16, type=int,\n",
        "                    metavar='N', help='mini-batch size (default: 256)')\n",
        "parser.add_argument('--lr', '--learning-rate', default=0.1, type=float,\n",
        "                    metavar='LR', help='initial learning rate')\n",
        "parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
        "                    help='momentum')\n",
        "parser.add_argument('--weight-decay', '--wd', default=1e-4, type=float,\n",
        "                    metavar='W', help='weight decay (default: 1e-4)')\n",
        "parser.add_argument('--print-freq', '-p', default=100, type=int,\n",
        "                    metavar='N', help='print frequency (default: 10)')\n",
        "parser.add_argument('--resume', default='', type=str, metavar='PATH',\n",
        "                    help='path to latest checkpoint (default: none)')\n",
        "parser.add_argument('-e', '--evaluate', dest='evaluate', action='store_true',\n",
        "                    help='evaluate model on validation set')\n",
        "parser.add_argument('--pretrained', dest='pretrained', action='store_true',\n",
        "                    help='use pre-trained model')\n",
        "parser.add_argument('--world-size', default=1, type=int,\n",
        "                    help='number of distributed processes')\n",
        "parser.add_argument('--dist-url', default='tcp://224.66.41.62:23456', type=str,\n",
        "                    help='url used to set up distributed training')\n",
        "parser.add_argument('--dist-backend', default='gloo', type=str,\n",
        "                    help='distributed backend')\n",
        "parser.add_argument('--seed', default=None, type=int, nargs='+',\n",
        "                    help='seed for initializing training. ')\n",
        "parser.add_argument('--gpu', default=None, type=int,\n",
        "                    help='GPU id to use.')\n",
        "parser.add_argument('--ksize', default=None, type=list,\n",
        "                    help='Manually select the eca module kernel size')\n",
        "parser.add_argument('--action', default='', type=str,\n",
        "                    help='other information.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZaHNkg66Ccz4"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    global args, best_prec1\n",
        "    #args = parser.parse_args()\n",
        "    args, _ = parser.parse_known_args()\n",
        "\n",
        "    if args.seed is not None:\n",
        "        random.seed(args.seed)\n",
        "        torch.manual_seed(args.seed)\n",
        "        cudnn.deterministic = True\n",
        "        warnings.warn('You have chosen to seed training. '\n",
        "                      'This will turn on the CUDNN deterministic setting, '\n",
        "                      'which can slow down your training considerably! '\n",
        "                      'You may see unexpected behavior when restarting '\n",
        "                      'from checkpoints.')\n",
        "    #args.gpu = 1\n",
        "    if args.gpu is not None:\n",
        "        warnings.warn('You have chosen a specific GPU. This will completely '\n",
        "                      'disable data parallelism.')\n",
        "\n",
        "    #args.distributed = args.world_size > 1\n",
        "    args.distributed = False\n",
        "\n",
        "    if args.distributed:\n",
        "        dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\n",
        "                                world_size=args.world_size)\n",
        "    torch.autograd.set_detect_anomaly(True)\n",
        "    # create model\n",
        "\n",
        "    args.arch = 'Apple_banana_orange'\n",
        "    filenameLOG = \"/content/drive/MyDrive/ML/checkpoints/%s/\"%(args.arch + '_' + args.action) + '/' + args.arch + '.txt'\n",
        "    #if not os.path.exists(pathout):\n",
        "    #    os.makedirs(pathout)\n",
        "    # get model\n",
        "    #model = get_model_new(args=args)\n",
        "    if args.pretrained:\n",
        "        print(\"=> using pre-trained model '{}'\".format(args.arch))\n",
        "        model = models.__dict__[args.arch](k_size=args.ksize, pretrained=True)\n",
        "    else:\n",
        "        model = Net(4)\n",
        "    if args.gpu is not None:\n",
        "        model = model.cuda(args.gpu)\n",
        "    elif args.distributed:\n",
        "        model.cuda()\n",
        "        model = torch.nn.parallel.DistributedDataParallel(model)\n",
        "    else:\n",
        "        model = torch.nn.DataParallel(model).cuda()\n",
        "\n",
        "    print(model)\n",
        "\n",
        "    # get the number of models parameters\n",
        "    print('Number of models parameters: {}'.format(\n",
        "        sum([p.data.nelement() for p in model.parameters()])))\n",
        "\n",
        "    # define loss function (criterion) and optimizer\n",
        "    train_loss_fn = LabelSmoothingCrossEntropy(smoothing=0.1).cuda(args.gpu)\n",
        "    criterion = nn.CrossEntropyLoss().cuda(args.gpu)\n",
        "\n",
        "    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
        "                                momentum=args.momentum,\n",
        "                                weight_decay=args.weight_decay)\n",
        "\n",
        "    # optionally resume from a checkpoint\n",
        "    if args.evaluate:\n",
        "        pathcheckpoint = \"/content/drive/MyDrive/ML/checkpoints/%s/\"%(args.arch + '_' + args.action) + \"model_best.pth.tar\"\n",
        "        if os.path.isfile(pathcheckpoint):\n",
        "            print(\"=> loading checkpoint '{}'\".format(pathcheckpoint))\n",
        "            checkpoint = torch.load(pathcheckpoint)\n",
        "            model.load_state_dict(checkpoint['state_dict'])\n",
        "            #optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "            del checkpoint\n",
        "        else:\n",
        "            print(\"=> no checkpoint found at '{}'\".format(pathcheckpoint))\n",
        "            return\n",
        "    if args.resume:\n",
        "        if os.path.isfile(args.resume):\n",
        "            print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
        "            checkpoint = torch.load(args.resume)\n",
        "            args.start_epoch = checkpoint['epoch']\n",
        "            best_prec1 = checkpoint['best_prec1']\n",
        "            model.load_state_dict(checkpoint['state_dict'])\n",
        "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
        "                  .format(args.resume, checkpoint['epoch']))\n",
        "            del checkpoint\n",
        "        else:\n",
        "            print(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
        "\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "    # Data loading code\n",
        "    traindir = os.path.join(args.data, 'train')\n",
        "    valdir = os.path.join(args.data, 'test')\n",
        "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "\n",
        "    train_dataset = datasets.ImageFolder(\n",
        "        traindir,\n",
        "        transforms.Compose([\n",
        "            transforms.RandomResizedCrop(224),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ])\n",
        "        )\n",
        "    # train_dataset = datasets.ImageFolder(\n",
        "    #     traindir,\n",
        "    #     transforms.Compose([\n",
        "    #         transforms.Resize(size=(256, 256)),\n",
        "    #         transforms.RandomCrop(224),\n",
        "    #         transforms.RandomHorizontalFlip(),\n",
        "    #         transforms.ColorJitter(0.4),\n",
        "    #         transforms.ToTensor(),\n",
        "    #         normalize\n",
        "    #     ]))\n",
        "\n",
        "    if args.distributed:\n",
        "        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n",
        "    else:\n",
        "        train_sampler = None\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),\n",
        "        num_workers=args.workers, pin_memory=True, sampler=train_sampler)\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        datasets.ImageFolder(valdir, transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ])),\n",
        "        batch_size=args.batch_size, shuffle=False,\n",
        "        num_workers=args.workers, pin_memory=True)\n",
        "    # val_loader = torch.utils.data.DataLoader(\n",
        "    #     datasets.ImageFolder(valdir, transforms.Compose([\n",
        "    #         transforms.Resize(size=(256, 256)),\n",
        "    #         transforms.CenterCrop(224),\n",
        "    #         transforms.ToTensor(),\n",
        "    #         normalize\n",
        "    #     ])),\n",
        "    #     batch_size=args.batch_size, shuffle=False,\n",
        "    #     num_workers=args.workers, pin_memory=True)\n",
        "    if args.evaluate:\n",
        "        m = time.time()\n",
        "        _, _ =validate(val_loader, model, criterion)\n",
        "        n = time.time()\n",
        "        print((n-m)/3600)\n",
        "        return\n",
        "\n",
        "    directory = \"/content/drive/MyDrive/ML/checkpoints/%s/\"%(args.arch + '_' + args.action)\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "    Loss_plot = {}\n",
        "    train_prec1_plot = {}\n",
        "    train_prec5_plot = {}\n",
        "    val_prec1_plot = {}\n",
        "    val_prec5_plot = {}\n",
        "    epoch_max = None\n",
        "    best_prec1 = 0\n",
        "    for epoch in range(args.start_epoch, args.epochs):\n",
        "        start_time = time.time()\n",
        "        if args.distributed:\n",
        "            train_sampler.set_epoch(epoch)\n",
        "        adjust_learning_rate(optimizer, epoch)\n",
        "\n",
        "        # train for one epoch\n",
        "        # train(train_loader, model, criterion, optimizer, epoch)\n",
        "        #loss_temp, train_prec1_temp, train_prec5_temp = train(train_loader, model, criterion, optimizer, epoch)\n",
        "        loss_temp, train_prec1_temp, train_prec5_temp = train(train_loader, model, train_loss_fn, optimizer, epoch)\n",
        "\n",
        "        Loss_plot[epoch] = loss_temp\n",
        "        train_prec1_plot[epoch] = train_prec1_temp\n",
        "        train_prec5_plot[epoch] = train_prec5_temp\n",
        "\n",
        "        # evaluate on validation set\n",
        "        # prec1 = validate(val_loader, model, criterion)\n",
        "        prec1, prec5 = validate(val_loader, model, criterion)\n",
        "        val_prec1_plot[epoch] = prec1\n",
        "        val_prec5_plot[epoch] = prec5\n",
        "\n",
        "        # remember best prec@1 and save checkpoint\n",
        "        is_best = prec1 > best_prec1\n",
        "        best_prec1 = max(prec1, best_prec1)\n",
        "        save_checkpoint({\n",
        "            'epoch': epoch + 1,\n",
        "            'arch': args.arch,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'best_prec1': best_prec1,\n",
        "            'optimizer' : optimizer.state_dict(),\n",
        "        }, is_best)\n",
        "\n",
        "        # 将Loss,train_prec1,train_prec5,val_prec1,val_prec5用.txt的文件存起来\n",
        "        data_save(directory + 'Loss_plot.txt', Loss_plot)\n",
        "        data_save(directory + 'train_prec1.txt', train_prec1_plot)\n",
        "        data_save(directory + 'train_prec5.txt', train_prec5_plot)\n",
        "        data_save(directory + 'val_prec1.txt', val_prec1_plot)\n",
        "        data_save(directory + 'val_prec5.txt', val_prec5_plot)\n",
        "\n",
        "        line = 'Epoch {}/{} summary: loss_train={:.5f}, acc_train={:.2f}%, loss_val={:.2f}, acc_val={:.2f}% (best: {:.2f}% @ epoch {})'.format(epoch, args.epochs, loss_temp, train_prec1_temp, 0, prec1, best_prec1, epoch_max)\n",
        "        wA.writeLogAcc(filenameLOG,line)\n",
        "        end_time = time.time()\n",
        "        time_value = (end_time - start_time) / 3600\n",
        "        print(\"-\" * 80)\n",
        "        print(time_value)\n",
        "        print(\"-\" * 80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pCC-UD9ICgGn"
      },
      "outputs": [],
      "source": [
        "def train(train_loader, model, criterion, optimizer, epoch):\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "    losses_batch = {}\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (input, target) in enumerate(train_loader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        if args.gpu is not None:\n",
        "            input = input.cuda(args.gpu, non_blocking=True)\n",
        "        target = target.cuda(args.gpu, non_blocking=True)\n",
        "\n",
        "        # compute output\n",
        "        output = model(input)\n",
        "\n",
        "        # Check for NaNs in output\n",
        "        if torch.isnan(output).any():\n",
        "            print(\"NaN detected in model output.\")\n",
        "            return None, None, None  # Returning None to stop further processing\n",
        "\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # Check for NaNs in loss\n",
        "        if torch.isnan(loss).any():\n",
        "            print(f\"NaN detected in loss at iteration {i}\")\n",
        "            return None, None, None\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        prec1, prec5 = accuracy(output, target, topk=(1, 2))\n",
        "        losses.update(loss.item(), input.size(0))\n",
        "        top1.update(prec1[0], input.size(0))\n",
        "        top5.update(prec5[0], input.size(0))\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        # Apply gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)  # Adjust max_norm as needed\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % args.print_freq == 0:\n",
        "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
        "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
        "                  'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
        "                   epoch, i, len(train_loader), batch_time=batch_time,\n",
        "                   data_time=data_time, loss=losses, top1=top1, top5=top5))\n",
        "\n",
        "    return losses.avg, top1.avg, top5.avg\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "b67hA12QCiwI"
      },
      "outputs": [],
      "source": [
        "def validate(val_loader, model, criterion):\n",
        "    batch_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        end = time.time()\n",
        "        for i, (input, target) in enumerate(val_loader):\n",
        "            if args.gpu is not None:\n",
        "                input = input.cuda(args.gpu, non_blocking=True)\n",
        "            target = target.cuda(args.gpu, non_blocking=True)\n",
        "\n",
        "            # compute output\n",
        "            output = model(input)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            # measure accuracy and record loss\n",
        "            prec1, prec5 = accuracy(output, target, topk=(1, 2))\n",
        "            losses.update(loss.item(), input.size(0))\n",
        "            top1.update(prec1[0], input.size(0))\n",
        "            top5.update(prec5[0], input.size(0))\n",
        "\n",
        "            # measure elapsed time\n",
        "            batch_time.update(time.time() - end)\n",
        "            end = time.time()\n",
        "\n",
        "            if i % args.print_freq == 0:\n",
        "                print('Test: [{0}/{1}]\\t'\n",
        "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                      'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
        "                      'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
        "                       i, len(val_loader), batch_time=batch_time, loss=losses,\n",
        "                       top1=top1, top5=top5))\n",
        "\n",
        "        print(' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}'\n",
        "              .format(top1=top1, top5=top5))\n",
        "\n",
        "    return top1.avg, top5.avg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "fte2WINCClSo"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
        "    directory = \"/content/drive/MyDrive/ML/checkpoints/%s/\"%(args.arch + '_' + args.action)\n",
        "\n",
        "    filename = directory + filename\n",
        "    torch.save(state, filename)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filename, directory + 'model_best.pth.tar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "AiaaUKXACnYZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "g52wrXXPCpRA"
      },
      "outputs": [],
      "source": [
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
        "    lr = args.lr * (0.1 ** (epoch // 30))\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            #correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
        "            correct_k = correct[:k].contiguous().view(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res\n",
        "\n",
        "\n",
        "def data_save(root, file):\n",
        "    # Check if the file exists, and if not, create it\n",
        "    if not os.path.exists(root):\n",
        "        with open(root, 'w'): pass  # Create an empty file if it doesn't exist\n",
        "\n",
        "    # Open the file and read lines\n",
        "    with open(root, 'r') as file_temp:\n",
        "        lines = file_temp.readlines()\n",
        "\n",
        "    # Initialize epoch value\n",
        "    if not lines:\n",
        "        epoch = -1\n",
        "    else:\n",
        "        epoch = lines[-1][:lines[-1].index(' ')]  # Get the epoch from the last line\n",
        "    epoch = int(epoch)\n",
        "\n",
        "    # Append new data to the file\n",
        "    with open(root, 'a') as file_temp:\n",
        "        for line in file:\n",
        "            if line > epoch:\n",
        "                file_temp.write(str(line) + \" \" + str(file[line]) + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EN3H11lHCtKI",
        "outputId": "34fa79ba-a70f-456f-e4a2-62045953b0cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataParallel(\n",
            "  (module): Net(\n",
            "    (conv0): Conv2d(3, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
            "    (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv7): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv8): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv9): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv10): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv11): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (maxpool2): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
            "    (avgpool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    (avgpool2): AvgPool2d(kernel_size=2, stride=4, padding=0)\n",
            "    (fc1): Linear(in_features=9408, out_features=1204, bias=True)\n",
            "    (fc2): Linear(in_features=1204, out_features=4, bias=True)\n",
            "    (relu): ReLU()\n",
            "  )\n",
            ")\n",
            "Number of models parameters: 17625864\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [0][0/104]\tTime 31.048 (31.048)\tData 14.747 (14.747)\tLoss 1.3720 (1.3720)\tPrec@1 37.500 (37.500)\tPrec@5 62.500 (62.500)\n",
            "Epoch: [0][100/104]\tTime 0.397 (0.718)\tData 0.000 (0.165)\tLoss 53.4484 (4.3789)\tPrec@1 43.750 (42.327)\tPrec@5 75.000 (73.020)\n",
            "Test: [0/11]\tTime 10.924 (10.924)\tLoss 0.6707 (0.6707)\tPrec@1 75.000 (75.000)\tPrec@5 100.000 (100.000)\n",
            " * Prec@1 63.804 Prec@5 90.184\n",
            "--------------------------------------------------------------------------------\n",
            "0.03398824883831872\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [1][0/104]\tTime 1.695 (1.695)\tData 1.184 (1.184)\tLoss 1.4228 (1.4228)\tPrec@1 12.500 (12.500)\tPrec@5 50.000 (50.000)\n",
            "Epoch: [1][100/104]\tTime 0.378 (0.411)\tData 0.000 (0.012)\tLoss 1.1553 (1.8080)\tPrec@1 43.750 (49.629)\tPrec@5 62.500 (78.527)\n",
            "Test: [0/11]\tTime 1.199 (1.199)\tLoss 0.8792 (0.8792)\tPrec@1 56.250 (56.250)\tPrec@5 100.000 (100.000)\n",
            " * Prec@1 86.503 Prec@5 98.160\n",
            "--------------------------------------------------------------------------------\n",
            "0.01295348929034339\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [2][0/104]\tTime 2.287 (2.287)\tData 1.764 (1.764)\tLoss 0.9765 (0.9765)\tPrec@1 50.000 (50.000)\tPrec@5 87.500 (87.500)\n",
            "Epoch: [2][100/104]\tTime 0.371 (0.400)\tData 0.000 (0.018)\tLoss 1.0270 (2.5261)\tPrec@1 62.500 (54.517)\tPrec@5 87.500 (80.507)\n",
            "Test: [0/11]\tTime 1.655 (1.655)\tLoss 1.1781 (1.1781)\tPrec@1 43.750 (43.750)\tPrec@5 93.750 (93.750)\n",
            " * Prec@1 80.982 Prec@5 97.546\n",
            "--------------------------------------------------------------------------------\n",
            "0.012661163409550985\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [3][0/104]\tTime 1.810 (1.810)\tData 1.284 (1.284)\tLoss 1.2742 (1.2742)\tPrec@1 25.000 (25.000)\tPrec@5 75.000 (75.000)\n",
            "Epoch: [3][100/104]\tTime 0.373 (0.395)\tData 0.000 (0.014)\tLoss 0.9859 (1.0935)\tPrec@1 62.500 (53.465)\tPrec@5 81.250 (82.859)\n",
            "Test: [0/11]\tTime 1.030 (1.030)\tLoss 0.7250 (0.7250)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            " * Prec@1 85.890 Prec@5 97.546\n",
            "--------------------------------------------------------------------------------\n",
            "0.0123484957880444\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [4][0/104]\tTime 3.222 (3.222)\tData 2.367 (2.367)\tLoss 0.8495 (0.8495)\tPrec@1 68.750 (68.750)\tPrec@5 81.250 (81.250)\n",
            "Epoch: [4][100/104]\tTime 0.370 (0.406)\tData 0.000 (0.024)\tLoss 1.0756 (28.3785)\tPrec@1 62.500 (49.257)\tPrec@5 87.500 (78.465)\n",
            "Test: [0/11]\tTime 0.998 (0.998)\tLoss 1.1840 (1.1840)\tPrec@1 43.750 (43.750)\tPrec@5 87.500 (87.500)\n",
            " * Prec@1 77.914 Prec@5 93.252\n",
            "--------------------------------------------------------------------------------\n",
            "0.012534299360381232\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [5][0/104]\tTime 2.558 (2.558)\tData 1.945 (1.945)\tLoss 0.9876 (0.9876)\tPrec@1 62.500 (62.500)\tPrec@5 87.500 (87.500)\n",
            "Epoch: [5][100/104]\tTime 0.369 (0.406)\tData 0.000 (0.020)\tLoss 0.9619 (1.3069)\tPrec@1 56.250 (52.661)\tPrec@5 93.750 (82.735)\n",
            "Test: [0/11]\tTime 1.159 (1.159)\tLoss 0.9087 (0.9087)\tPrec@1 75.000 (75.000)\tPrec@5 100.000 (100.000)\n",
            " * Prec@1 80.982 Prec@5 98.773\n",
            "--------------------------------------------------------------------------------\n",
            "0.012599116166432698\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [6][0/104]\tTime 2.046 (2.046)\tData 1.478 (1.478)\tLoss 1.0288 (1.0288)\tPrec@1 50.000 (50.000)\tPrec@5 87.500 (87.500)\n",
            "Epoch: [6][100/104]\tTime 0.366 (0.395)\tData 0.000 (0.015)\tLoss 1.0032 (1.2123)\tPrec@1 56.250 (52.970)\tPrec@5 75.000 (84.097)\n",
            "Test: [0/11]\tTime 1.161 (1.161)\tLoss 0.9095 (0.9095)\tPrec@1 62.500 (62.500)\tPrec@5 100.000 (100.000)\n",
            " * Prec@1 74.847 Prec@5 98.773\n",
            "--------------------------------------------------------------------------------\n",
            "0.012315535479121738\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [7][0/104]\tTime 1.792 (1.792)\tData 1.266 (1.266)\tLoss 1.0122 (1.0122)\tPrec@1 56.250 (56.250)\tPrec@5 75.000 (75.000)\n",
            "Epoch: [7][100/104]\tTime 0.370 (0.393)\tData 0.000 (0.013)\tLoss 1.2827 (1.5064)\tPrec@1 31.250 (52.599)\tPrec@5 75.000 (82.116)\n",
            "Test: [0/11]\tTime 1.707 (1.707)\tLoss 0.7426 (0.7426)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            " * Prec@1 87.117 Prec@5 99.386\n",
            "--------------------------------------------------------------------------------\n",
            "0.01269607232676612\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [8][0/104]\tTime 1.848 (1.848)\tData 1.259 (1.259)\tLoss 1.0079 (1.0079)\tPrec@1 56.250 (56.250)\tPrec@5 87.500 (87.500)\n",
            "Epoch: [8][100/104]\tTime 0.363 (0.393)\tData 0.000 (0.013)\tLoss 0.9701 (3.7316)\tPrec@1 62.500 (52.290)\tPrec@5 87.500 (79.889)\n",
            "Test: [0/11]\tTime 1.542 (1.542)\tLoss 1.2944 (1.2944)\tPrec@1 6.250 (6.250)\tPrec@5 75.000 (75.000)\n",
            " * Prec@1 74.233 Prec@5 94.479\n",
            "--------------------------------------------------------------------------------\n",
            "0.012583722935782539\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [9][0/104]\tTime 1.950 (1.950)\tData 1.456 (1.456)\tLoss 0.9268 (0.9268)\tPrec@1 56.250 (56.250)\tPrec@5 93.750 (93.750)\n",
            "Epoch: [9][100/104]\tTime 0.365 (0.390)\tData 0.000 (0.015)\tLoss 0.9849 (1.0697)\tPrec@1 56.250 (59.344)\tPrec@5 75.000 (84.715)\n",
            "Test: [0/11]\tTime 1.066 (1.066)\tLoss 0.4944 (0.4944)\tPrec@1 81.250 (81.250)\tPrec@5 93.750 (93.750)\n",
            " * Prec@1 88.344 Prec@5 97.546\n",
            "--------------------------------------------------------------------------------\n",
            "0.012446452644136217\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [10][0/104]\tTime 2.558 (2.558)\tData 2.047 (2.047)\tLoss 3.8812 (3.8812)\tPrec@1 31.250 (31.250)\tPrec@5 62.500 (62.500)\n",
            "Epoch: [10][100/104]\tTime 0.362 (0.394)\tData 0.000 (0.021)\tLoss 0.9387 (1.5235)\tPrec@1 75.000 (55.755)\tPrec@5 87.500 (83.787)\n",
            "Test: [0/11]\tTime 1.055 (1.055)\tLoss 0.7171 (0.7171)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            " * Prec@1 88.344 Prec@5 96.933\n",
            "--------------------------------------------------------------------------------\n",
            "0.012467942900127834\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [11][0/104]\tTime 3.370 (3.370)\tData 2.821 (2.821)\tLoss 1.1235 (1.1235)\tPrec@1 68.750 (68.750)\tPrec@5 68.750 (68.750)\n",
            "Epoch: [11][100/104]\tTime 0.373 (0.402)\tData 0.000 (0.028)\tLoss 1.0644 (1.2462)\tPrec@1 50.000 (46.906)\tPrec@5 75.000 (75.681)\n",
            "Test: [0/11]\tTime 1.111 (1.111)\tLoss 1.0477 (1.0477)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            " * Prec@1 25.767 Prec@5 38.650\n",
            "--------------------------------------------------------------------------------\n",
            "0.012466103037198384\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [12][0/104]\tTime 3.105 (3.105)\tData 2.378 (2.378)\tLoss 1.1881 (1.1881)\tPrec@1 37.500 (37.500)\tPrec@5 62.500 (62.500)\n",
            "Epoch: [12][100/104]\tTime 0.359 (0.400)\tData 0.000 (0.024)\tLoss 1.0031 (1.2083)\tPrec@1 62.500 (43.131)\tPrec@5 87.500 (73.144)\n",
            "Test: [0/11]\tTime 0.927 (0.927)\tLoss 0.8829 (0.8829)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            " * Prec@1 85.276 Prec@5 96.933\n",
            "--------------------------------------------------------------------------------\n",
            "0.012494671609666613\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [13][0/104]\tTime 1.932 (1.932)\tData 1.229 (1.229)\tLoss 1.0509 (1.0509)\tPrec@1 56.250 (56.250)\tPrec@5 68.750 (68.750)\n",
            "Epoch: [13][100/104]\tTime 0.357 (0.384)\tData 0.000 (0.013)\tLoss 1.1856 (1.1962)\tPrec@1 37.500 (45.421)\tPrec@5 62.500 (77.042)\n",
            "Test: [0/11]\tTime 1.140 (1.140)\tLoss 1.1856 (1.1856)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
            " * Prec@1 61.350 Prec@5 73.620\n",
            "--------------------------------------------------------------------------------\n",
            "0.011983324421776666\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [14][0/104]\tTime 2.125 (2.125)\tData 1.518 (1.518)\tLoss 1.1629 (1.1629)\tPrec@1 56.250 (56.250)\tPrec@5 87.500 (87.500)\n",
            "Epoch: [14][100/104]\tTime 0.356 (0.383)\tData 0.000 (0.016)\tLoss 1.1674 (1.1855)\tPrec@1 43.750 (39.295)\tPrec@5 75.000 (70.730)\n",
            "Test: [0/11]\tTime 1.575 (1.575)\tLoss 1.4049 (1.4049)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
            " * Prec@1 61.350 Prec@5 73.620\n",
            "--------------------------------------------------------------------------------\n",
            "0.012359009981155395\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [15][0/104]\tTime 1.504 (1.504)\tData 1.068 (1.068)\tLoss 1.1619 (1.1619)\tPrec@1 31.250 (31.250)\tPrec@5 81.250 (81.250)\n",
            "Epoch: [15][100/104]\tTime 0.352 (0.375)\tData 0.000 (0.011)\tLoss 1.1704 (1.1851)\tPrec@1 37.500 (39.728)\tPrec@5 81.250 (70.235)\n",
            "Test: [0/11]\tTime 1.204 (1.204)\tLoss 1.3703 (1.3703)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
            " * Prec@1 12.270 Prec@5 73.620\n",
            "--------------------------------------------------------------------------------\n",
            "0.011816042727894252\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [16][0/104]\tTime 3.314 (3.314)\tData 2.427 (2.427)\tLoss 1.2158 (1.2158)\tPrec@1 25.000 (25.000)\tPrec@5 62.500 (62.500)\n",
            "Epoch: [16][100/104]\tTime 0.353 (0.395)\tData 0.000 (0.024)\tLoss 1.1384 (1.1831)\tPrec@1 56.250 (40.285)\tPrec@5 75.000 (69.493)\n",
            "Test: [0/11]\tTime 1.107 (1.107)\tLoss 1.1943 (1.1943)\tPrec@1 0.000 (0.000)\tPrec@5 100.000 (100.000)\n",
            " * Prec@1 61.350 Prec@5 87.730\n",
            "--------------------------------------------------------------------------------\n",
            "0.012365792791048685\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [17][0/104]\tTime 1.979 (1.979)\tData 1.291 (1.291)\tLoss 1.0680 (1.0680)\tPrec@1 68.750 (68.750)\tPrec@5 93.750 (93.750)\n",
            "Epoch: [17][100/104]\tTime 0.354 (0.387)\tData 0.000 (0.013)\tLoss 1.2082 (1.1830)\tPrec@1 31.250 (39.418)\tPrec@5 50.000 (70.978)\n",
            "Test: [0/11]\tTime 1.109 (1.109)\tLoss 1.1900 (1.1900)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
            " * Prec@1 61.350 Prec@5 73.620\n",
            "--------------------------------------------------------------------------------\n",
            "0.012027988897429572\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [18][0/104]\tTime 1.514 (1.514)\tData 1.050 (1.050)\tLoss 1.1919 (1.1919)\tPrec@1 31.250 (31.250)\tPrec@5 75.000 (75.000)\n",
            "Epoch: [18][100/104]\tTime 0.354 (0.380)\tData 0.000 (0.011)\tLoss 1.1990 (1.1892)\tPrec@1 25.000 (38.800)\tPrec@5 68.750 (69.493)\n",
            "Test: [0/11]\tTime 1.856 (1.856)\tLoss 1.3618 (1.3618)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
            " * Prec@1 61.350 Prec@5 73.620\n",
            "--------------------------------------------------------------------------------\n",
            "0.012126747369766235\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [19][0/104]\tTime 1.957 (1.957)\tData 1.456 (1.456)\tLoss 1.1545 (1.1545)\tPrec@1 43.750 (43.750)\tPrec@5 81.250 (81.250)\n",
            "Epoch: [19][100/104]\tTime 0.351 (0.382)\tData 0.000 (0.015)\tLoss 1.1675 (1.1895)\tPrec@1 43.750 (39.295)\tPrec@5 75.000 (70.978)\n",
            "Test: [0/11]\tTime 1.074 (1.074)\tLoss 1.2178 (1.2178)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
            " * Prec@1 61.350 Prec@5 73.620\n",
            "--------------------------------------------------------------------------------\n",
            "0.011902066071828206\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [20][0/104]\tTime 3.026 (3.026)\tData 2.405 (2.405)\tLoss 1.1605 (1.1605)\tPrec@1 50.000 (50.000)\tPrec@5 87.500 (87.500)\n",
            "Epoch: [20][100/104]\tTime 0.356 (0.394)\tData 0.000 (0.024)\tLoss 1.1912 (1.1845)\tPrec@1 37.500 (40.903)\tPrec@5 75.000 (68.626)\n",
            "Test: [0/11]\tTime 1.029 (1.029)\tLoss 1.5455 (1.5455)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
            " * Prec@1 61.350 Prec@5 73.620\n",
            "--------------------------------------------------------------------------------\n",
            "0.012205688688490125\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [21][0/104]\tTime 1.809 (1.809)\tData 1.278 (1.278)\tLoss 1.2508 (1.2508)\tPrec@1 37.500 (37.500)\tPrec@5 56.250 (56.250)\n",
            "Epoch: [21][100/104]\tTime 0.355 (0.380)\tData 0.000 (0.013)\tLoss 1.1869 (1.1893)\tPrec@1 43.750 (39.604)\tPrec@5 68.750 (68.379)\n",
            "Test: [0/11]\tTime 2.182 (2.182)\tLoss 1.4989 (1.4989)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
            " * Prec@1 61.350 Prec@5 73.620\n",
            "--------------------------------------------------------------------------------\n",
            "0.012186775472429063\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [22][0/104]\tTime 2.295 (2.295)\tData 1.760 (1.760)\tLoss 1.1991 (1.1991)\tPrec@1 31.250 (31.250)\tPrec@5 75.000 (75.000)\n",
            "Epoch: [22][100/104]\tTime 0.354 (0.382)\tData 0.000 (0.018)\tLoss 1.1959 (1.1866)\tPrec@1 50.000 (38.428)\tPrec@5 68.750 (70.050)\n",
            "Test: [0/11]\tTime 1.166 (1.166)\tLoss 1.3974 (1.3974)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
            " * Prec@1 61.350 Prec@5 73.620\n",
            "--------------------------------------------------------------------------------\n",
            "0.011990798976686265\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [23][0/104]\tTime 3.667 (3.667)\tData 2.965 (2.965)\tLoss 1.2516 (1.2516)\tPrec@1 31.250 (31.250)\tPrec@5 50.000 (50.000)\n",
            "Epoch: [23][100/104]\tTime 0.355 (0.393)\tData 0.000 (0.030)\tLoss 1.1501 (1.1880)\tPrec@1 56.250 (38.923)\tPrec@5 75.000 (69.864)\n",
            "Test: [0/11]\tTime 1.059 (1.059)\tLoss 1.1443 (1.1443)\tPrec@1 0.000 (0.000)\tPrec@5 100.000 (100.000)\n",
            " * Prec@1 61.350 Prec@5 87.730\n",
            "--------------------------------------------------------------------------------\n",
            "0.012239171796374852\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [24][0/104]\tTime 3.011 (3.011)\tData 2.348 (2.348)\tLoss 1.1714 (1.1714)\tPrec@1 43.750 (43.750)\tPrec@5 75.000 (75.000)\n",
            "Epoch: [24][100/104]\tTime 0.355 (0.396)\tData 0.000 (0.024)\tLoss 1.2910 (1.1896)\tPrec@1 31.250 (38.738)\tPrec@5 62.500 (70.359)\n",
            "Test: [0/11]\tTime 1.176 (1.176)\tLoss 1.6464 (1.6464)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
            " * Prec@1 61.350 Prec@5 73.620\n",
            "--------------------------------------------------------------------------------\n",
            "0.012277573413319058\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [25][0/104]\tTime 2.437 (2.437)\tData 1.771 (1.771)\tLoss 1.2056 (1.2056)\tPrec@1 43.750 (43.750)\tPrec@5 68.750 (68.750)\n",
            "Epoch: [25][100/104]\tTime 0.356 (0.386)\tData 0.000 (0.018)\tLoss 1.1910 (1.1908)\tPrec@1 37.500 (39.109)\tPrec@5 68.750 (69.183)\n",
            "Test: [0/11]\tTime 1.993 (1.993)\tLoss 1.2036 (1.2036)\tPrec@1 0.000 (0.000)\tPrec@5 100.000 (100.000)\n",
            " * Prec@1 61.350 Prec@5 87.730\n",
            "--------------------------------------------------------------------------------\n",
            "0.012343935436672634\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [26][0/104]\tTime 2.372 (2.372)\tData 1.762 (1.762)\tLoss 1.1308 (1.1308)\tPrec@1 62.500 (62.500)\tPrec@5 62.500 (62.500)\n",
            "Epoch: [26][100/104]\tTime 0.354 (0.387)\tData 0.000 (0.018)\tLoss 1.1220 (1.1838)\tPrec@1 56.250 (39.233)\tPrec@5 81.250 (70.545)\n",
            "Test: [0/11]\tTime 1.126 (1.126)\tLoss 1.4278 (1.4278)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
            " * Prec@1 61.350 Prec@5 73.620\n",
            "--------------------------------------------------------------------------------\n",
            "0.01223295463456048\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [27][0/104]\tTime 3.353 (3.353)\tData 2.517 (2.517)\tLoss 1.0117 (1.0117)\tPrec@1 75.000 (75.000)\tPrec@5 87.500 (87.500)\n",
            "Epoch: [27][100/104]\tTime 0.354 (0.391)\tData 0.000 (0.025)\tLoss 1.1962 (1.1873)\tPrec@1 37.500 (39.480)\tPrec@5 68.750 (69.493)\n",
            "Test: [0/11]\tTime 1.272 (1.272)\tLoss 1.3080 (1.3080)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
            " * Prec@1 61.350 Prec@5 73.620\n",
            "--------------------------------------------------------------------------------\n",
            "0.012177543375227187\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [28][0/104]\tTime 1.822 (1.822)\tData 1.301 (1.301)\tLoss 1.1548 (1.1548)\tPrec@1 37.500 (37.500)\tPrec@5 87.500 (87.500)\n",
            "Epoch: [28][100/104]\tTime 0.360 (0.386)\tData 0.000 (0.013)\tLoss 1.2293 (1.1836)\tPrec@1 18.750 (38.304)\tPrec@5 62.500 (70.359)\n",
            "Test: [0/11]\tTime 1.229 (1.229)\tLoss 1.3169 (1.3169)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
            " * Prec@1 61.350 Prec@5 73.620\n",
            "--------------------------------------------------------------------------------\n",
            "0.012075321343210009\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [29][0/104]\tTime 2.178 (2.178)\tData 1.541 (1.541)\tLoss 1.1367 (1.1367)\tPrec@1 62.500 (62.500)\tPrec@5 81.250 (81.250)\n",
            "Epoch: [29][100/104]\tTime 0.353 (0.384)\tData 0.000 (0.016)\tLoss 1.1790 (1.1842)\tPrec@1 43.750 (39.790)\tPrec@5 62.500 (70.111)\n",
            "Test: [0/11]\tTime 1.999 (1.999)\tLoss 1.2037 (1.2037)\tPrec@1 0.000 (0.000)\tPrec@5 100.000 (100.000)\n",
            " * Prec@1 61.350 Prec@5 87.730\n",
            "--------------------------------------------------------------------------------\n",
            "0.012268352972136604\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [30][0/104]\tTime 1.646 (1.646)\tData 1.160 (1.160)\tLoss 1.1194 (1.1194)\tPrec@1 62.500 (62.500)\tPrec@5 75.000 (75.000)\n",
            "Epoch: [30][100/104]\tTime 0.354 (0.379)\tData 0.000 (0.012)\tLoss 1.1600 (1.1783)\tPrec@1 50.000 (41.089)\tPrec@5 62.500 (69.493)\n",
            "Test: [0/11]\tTime 1.229 (1.229)\tLoss 1.2100 (1.2100)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
            " * Prec@1 61.350 Prec@5 73.620\n",
            "--------------------------------------------------------------------------------\n",
            "0.011968978378507826\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [31][0/104]\tTime 3.455 (3.455)\tData 2.602 (2.602)\tLoss 1.1987 (1.1987)\tPrec@1 31.250 (31.250)\tPrec@5 62.500 (62.500)\n",
            "Epoch: [31][100/104]\tTime 0.356 (0.395)\tData 0.000 (0.026)\tLoss 1.1881 (1.1775)\tPrec@1 37.500 (41.151)\tPrec@5 75.000 (70.235)\n",
            "Test: [0/11]\tTime 1.156 (1.156)\tLoss 1.2957 (1.2957)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
            " * Prec@1 61.350 Prec@5 73.620\n",
            "--------------------------------------------------------------------------------\n",
            "0.01227271384663052\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [32][0/104]\tTime 2.443 (2.443)\tData 1.899 (1.899)\tLoss 1.0640 (1.0640)\tPrec@1 75.000 (75.000)\tPrec@5 87.500 (87.500)\n",
            "Epoch: [32][100/104]\tTime 0.358 (0.387)\tData 0.000 (0.019)\tLoss 1.1896 (1.1772)\tPrec@1 37.500 (41.275)\tPrec@5 56.250 (70.730)\n",
            "Test: [0/11]\tTime 1.226 (1.226)\tLoss 1.2034 (1.2034)\tPrec@1 0.000 (0.000)\tPrec@5 100.000 (100.000)\n",
            " * Prec@1 61.350 Prec@5 87.730\n",
            "--------------------------------------------------------------------------------\n",
            "0.012081365784009297\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [33][0/104]\tTime 2.127 (2.127)\tData 1.591 (1.591)\tLoss 1.1148 (1.1148)\tPrec@1 68.750 (68.750)\tPrec@5 87.500 (87.500)\n",
            "Epoch: [33][100/104]\tTime 0.353 (0.384)\tData 0.000 (0.016)\tLoss 1.2827 (1.1786)\tPrec@1 12.500 (41.089)\tPrec@5 31.250 (69.802)\n",
            "Test: [0/11]\tTime 1.866 (1.866)\tLoss 1.2762 (1.2762)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
            " * Prec@1 61.350 Prec@5 73.620\n",
            "--------------------------------------------------------------------------------\n",
            "0.012245488630400763\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [34][0/104]\tTime 2.502 (2.502)\tData 2.004 (2.004)\tLoss 1.2164 (1.2164)\tPrec@1 25.000 (25.000)\tPrec@5 81.250 (81.250)\n",
            "Epoch: [34][100/104]\tTime 0.357 (0.385)\tData 0.000 (0.020)\tLoss 1.2601 (1.1785)\tPrec@1 18.750 (40.903)\tPrec@5 43.750 (69.554)\n",
            "Test: [0/11]\tTime 1.216 (1.216)\tLoss 1.2865 (1.2865)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
            " * Prec@1 61.350 Prec@5 73.620\n",
            "--------------------------------------------------------------------------------\n",
            "0.01207067264450921\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [35][0/104]\tTime 3.469 (3.469)\tData 2.760 (2.760)\tLoss 1.1948 (1.1948)\tPrec@1 37.500 (37.500)\tPrec@5 56.250 (56.250)\n",
            "Epoch: [35][100/104]\tTime 0.354 (0.421)\tData 0.000 (0.028)\tLoss 1.2260 (1.1798)\tPrec@1 31.250 (40.656)\tPrec@5 37.500 (68.502)\n",
            "Test: [0/11]\tTime 1.394 (1.394)\tLoss 1.2708 (1.2708)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
            " * Prec@1 61.350 Prec@5 73.620\n",
            "--------------------------------------------------------------------------------\n",
            "0.013198648360040453\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [36][0/104]\tTime 2.165 (2.165)\tData 1.373 (1.373)\tLoss 1.1333 (1.1333)\tPrec@1 56.250 (56.250)\tPrec@5 81.250 (81.250)\n",
            "Epoch: [36][100/104]\tTime 0.352 (0.403)\tData 0.000 (0.014)\tLoss 1.1675 (1.1780)\tPrec@1 43.750 (40.965)\tPrec@5 75.000 (70.668)\n",
            "Test: [0/11]\tTime 1.212 (1.212)\tLoss 1.2860 (1.2860)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
            " * Prec@1 61.350 Prec@5 73.620\n",
            "--------------------------------------------------------------------------------\n",
            "0.012503953046268886\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [37][0/104]\tTime 1.084 (1.084)\tData 0.698 (0.698)\tLoss 1.1835 (1.1835)\tPrec@1 37.500 (37.500)\tPrec@5 75.000 (75.000)\n",
            "Epoch: [37][100/104]\tTime 0.353 (0.380)\tData 0.000 (0.014)\tLoss 1.1794 (1.1786)\tPrec@1 43.750 (41.027)\tPrec@5 62.500 (69.864)\n",
            "Test: [0/11]\tTime 2.039 (2.039)\tLoss 1.2802 (1.2802)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
            " * Prec@1 61.350 Prec@5 73.620\n",
            "--------------------------------------------------------------------------------\n",
            "0.012170673542552524\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [38][0/104]\tTime 2.302 (2.302)\tData 1.739 (1.739)\tLoss 1.1769 (1.1769)\tPrec@1 37.500 (37.500)\tPrec@5 81.250 (81.250)\n",
            "Epoch: [38][100/104]\tTime 0.355 (0.384)\tData 0.000 (0.018)\tLoss 1.1398 (1.1784)\tPrec@1 56.250 (40.903)\tPrec@5 75.000 (71.163)\n",
            "Test: [0/11]\tTime 1.013 (1.013)\tLoss 1.2594 (1.2594)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
            " * Prec@1 61.350 Prec@5 73.620\n",
            "--------------------------------------------------------------------------------\n",
            "0.012010340227021112\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [39][0/104]\tTime 2.773 (2.773)\tData 2.152 (2.152)\tLoss 1.1836 (1.1836)\tPrec@1 37.500 (37.500)\tPrec@5 75.000 (75.000)\n",
            "Epoch: [39][100/104]\tTime 0.353 (0.396)\tData 0.000 (0.022)\tLoss 1.1488 (1.1775)\tPrec@1 50.000 (41.151)\tPrec@5 81.250 (70.854)\n",
            "Test: [0/11]\tTime 1.276 (1.276)\tLoss 1.2504 (1.2504)\tPrec@1 0.000 (0.000)\tPrec@5 100.000 (100.000)\n",
            " * Prec@1 61.350 Prec@5 87.730\n",
            "--------------------------------------------------------------------------------\n",
            "0.01231101459927029\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [40][0/104]\tTime 2.315 (2.315)\tData 1.725 (1.725)\tLoss 1.1293 (1.1293)\tPrec@1 56.250 (56.250)\tPrec@5 75.000 (75.000)\n",
            "Epoch: [40][100/104]\tTime 0.354 (0.385)\tData 0.000 (0.018)\tLoss 1.1960 (1.1769)\tPrec@1 37.500 (41.460)\tPrec@5 62.500 (71.349)\n",
            "Test: [0/11]\tTime 1.803 (1.803)\tLoss 1.3045 (1.3045)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
            " * Prec@1 61.350 Prec@5 73.620\n",
            "--------------------------------------------------------------------------------\n",
            "0.012225435707304213\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [41][0/104]\tTime 1.861 (1.861)\tData 1.223 (1.223)\tLoss 1.2428 (1.2428)\tPrec@1 31.250 (31.250)\tPrec@5 31.250 (31.250)\n",
            "Epoch: [41][100/104]\tTime 0.354 (0.381)\tData 0.000 (0.013)\tLoss 1.2218 (1.1776)\tPrec@1 25.000 (41.213)\tPrec@5 62.500 (70.730)\n",
            "Test: [0/11]\tTime 1.084 (1.084)\tLoss 1.2872 (1.2872)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
            " * Prec@1 61.350 Prec@5 73.620\n",
            "--------------------------------------------------------------------------------\n",
            "0.011939721571074592\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [42][0/104]\tTime 3.475 (3.475)\tData 2.485 (2.485)\tLoss 1.2227 (1.2227)\tPrec@1 18.750 (18.750)\tPrec@5 75.000 (75.000)\n",
            "Epoch: [42][100/104]\tTime 0.357 (0.393)\tData 0.000 (0.025)\tLoss 1.2670 (1.1778)\tPrec@1 12.500 (41.213)\tPrec@5 43.750 (71.040)\n",
            "Test: [0/11]\tTime 1.214 (1.214)\tLoss 1.2540 (1.2540)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
            " * Prec@1 61.350 Prec@5 73.620\n",
            "--------------------------------------------------------------------------------\n",
            "0.01224911285771264\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [43][0/104]\tTime 1.195 (1.195)\tData 0.753 (0.753)\tLoss 1.1888 (1.1888)\tPrec@1 37.500 (37.500)\tPrec@5 62.500 (62.500)\n",
            "Epoch: [43][100/104]\tTime 0.356 (0.385)\tData 0.000 (0.015)\tLoss 1.1720 (1.1785)\tPrec@1 43.750 (40.965)\tPrec@5 62.500 (70.545)\n",
            "Test: [0/11]\tTime 1.243 (1.243)\tLoss 1.2377 (1.2377)\tPrec@1 0.000 (0.000)\tPrec@5 100.000 (100.000)\n",
            " * Prec@1 61.350 Prec@5 87.730\n",
            "--------------------------------------------------------------------------------\n",
            "0.012014322413338555\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [44][0/104]\tTime 2.297 (2.297)\tData 1.736 (1.736)\tLoss 1.1699 (1.1699)\tPrec@1 43.750 (43.750)\tPrec@5 68.750 (68.750)\n",
            "Epoch: [44][100/104]\tTime 0.353 (0.385)\tData 0.000 (0.018)\tLoss 1.1477 (1.1782)\tPrec@1 50.000 (41.027)\tPrec@5 100.000 (70.173)\n",
            "Test: [0/11]\tTime 1.828 (1.828)\tLoss 1.2256 (1.2256)\tPrec@1 0.000 (0.000)\tPrec@5 100.000 (100.000)\n",
            " * Prec@1 61.350 Prec@5 87.730\n",
            "--------------------------------------------------------------------------------\n",
            "0.01226492550637987\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [45][0/104]\tTime 2.106 (2.106)\tData 1.473 (1.473)\tLoss 1.2194 (1.2194)\tPrec@1 25.000 (25.000)\tPrec@5 62.500 (62.500)\n",
            "Epoch: [45][100/104]\tTime 0.351 (0.380)\tData 0.000 (0.015)\tLoss 1.1608 (1.1784)\tPrec@1 50.000 (40.903)\tPrec@5 68.750 (70.854)\n",
            "Test: [0/11]\tTime 1.164 (1.164)\tLoss 1.2375 (1.2375)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
            " * Prec@1 61.350 Prec@5 73.620\n",
            "--------------------------------------------------------------------------------\n",
            "0.011962159408463372\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [46][0/104]\tTime 3.359 (3.359)\tData 2.281 (2.281)\tLoss 1.1983 (1.1983)\tPrec@1 31.250 (31.250)\tPrec@5 75.000 (75.000)\n",
            "Epoch: [46][100/104]\tTime 0.356 (0.395)\tData 0.000 (0.023)\tLoss 1.2031 (1.1775)\tPrec@1 31.250 (41.337)\tPrec@5 56.250 (70.916)\n",
            "Test: [0/11]\tTime 1.153 (1.153)\tLoss 1.2255 (1.2255)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
            " * Prec@1 61.350 Prec@5 73.620\n",
            "--------------------------------------------------------------------------------\n",
            "0.012286734912130568\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [47][0/104]\tTime 2.208 (2.208)\tData 1.568 (1.568)\tLoss 1.1853 (1.1853)\tPrec@1 37.500 (37.500)\tPrec@5 81.250 (81.250)\n",
            "Epoch: [47][100/104]\tTime 0.358 (0.387)\tData 0.000 (0.016)\tLoss 1.1757 (1.1782)\tPrec@1 43.750 (41.213)\tPrec@5 68.750 (70.297)\n",
            "Test: [0/11]\tTime 1.233 (1.233)\tLoss 1.2719 (1.2719)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
            " * Prec@1 61.350 Prec@5 73.620\n",
            "--------------------------------------------------------------------------------\n",
            "0.01211020674970415\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [48][0/104]\tTime 1.964 (1.964)\tData 1.329 (1.329)\tLoss 1.1868 (1.1868)\tPrec@1 37.500 (37.500)\tPrec@5 68.750 (68.750)\n",
            "Epoch: [48][100/104]\tTime 0.355 (0.382)\tData 0.000 (0.014)\tLoss 1.1899 (1.1783)\tPrec@1 37.500 (40.903)\tPrec@5 62.500 (69.493)\n",
            "Test: [0/11]\tTime 1.477 (1.477)\tLoss 1.2635 (1.2635)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
            " * Prec@1 61.350 Prec@5 73.620\n",
            "--------------------------------------------------------------------------------\n",
            "0.01223518192768097\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: [49][0/104]\tTime 1.935 (1.935)\tData 1.371 (1.371)\tLoss 1.1293 (1.1293)\tPrec@1 56.250 (56.250)\tPrec@5 87.500 (87.500)\n",
            "Epoch: [49][100/104]\tTime 0.353 (0.378)\tData 0.000 (0.014)\tLoss 1.1910 (1.1782)\tPrec@1 37.500 (41.151)\tPrec@5 62.500 (70.050)\n",
            "Test: [0/11]\tTime 1.072 (1.072)\tLoss 1.2755 (1.2755)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
            " * Prec@1 61.350 Prec@5 73.620\n",
            "--------------------------------------------------------------------------------\n",
            "0.01181319448682997\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
